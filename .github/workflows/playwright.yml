name: Playwright Tests

on:
  push:
  pull_request:

jobs:
  run-playwright-tests:
    name: Run Playwright Tests
    runs-on: ubuntu-latest

    env:
      TESTDINO_TOKEN: ${{ secrets.TESTDINO_TOKEN }}

    strategy:
      fail-fast: false
      matrix:
        shardIndex: [1, 2, 3, 4, 5]
        shardTotal: [5]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-playwright pytest-playwright-json pytest-html pytest-xdist pytest-shard
          pip install testdino
          playwright install --with-deps chromium

      - name: Run Playwright Tests
        shell: bash
        env:
          TESTDINO_TOKEN: ${{ secrets.TESTDINO_TOKEN }}
          SHARD_INDEX: ${{ matrix.shardIndex }}
          SHARD_TOTAL: ${{ matrix.shardTotal }}
        run: |
          mkdir -p test-results

          # Case 1: Re-run failed jobs â†’ run only failed tests
          if [[ "${{ github.run_attempt }}" -gt 1 ]]; then

            testdino last-failed --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }} --token="$TESTDINO_TOKEN" > last-failed-flags.txt
            FAILED_TESTS="$(cat last-failed-flags.txt | tail -1)"

            if [[ -z "$FAILED_TESTS" ]]; then
              exit 0
            fi

            # IMPORTANT: Use eval to preserve quotes in the -k expression
            # This matches the JavaScript workflow pattern and ensures quotes are preserved
            eval "pytest $FAILED_TESTS --playwright-json=test-results/report.json --html=test-results/index.html --self-contained-html -p no:selenium -v" || true
            exit 0
          fi

          # Case 2: Normal execution (first run) with sharding
          # pytest-shard uses 0-indexed shard IDs, so subtract 1 from SHARD_INDEX
          SHARD_ID=$(( $SHARD_INDEX - 1 ))
          pytest \
            --shard-id=$SHARD_ID \
            --num-shards=$SHARD_TOTAL \
            --playwright-json=test-results/report.json \
            --html=test-results/index.html \
            --self-contained-html \
            -p no:selenium \
            -v || true

      - name: Upload HTML report
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.shardIndex }}
          path: test-results/
          retention-days: 1

      - name: Cache testdino last failed metadata
        if: always()
        env:
          TESTDINO_TOKEN: ${{ secrets.TESTDINO_TOKEN }}
          SHARD_INDEX: ${{ matrix.shardIndex }}
          SHARD_TOTAL: ${{ matrix.shardTotal }}
        run: |
          if [ -n "$TESTDINO_TOKEN" ]; then
            testdino cache --working-dir test-results --token="$TESTDINO_TOKEN"
          fi

  playwright-tests-succeeded:
    name: Check Playwright Tests Status
    if: ${{ always() }}
    needs:
      - run-playwright-tests
    runs-on: ubuntu-latest
    steps:
      - name: Ensure the tests succeeded
        shell: bash
        run: |
          if [[ "${{ needs.run-playwright-tests.result }}" == "success" || "${{ needs.run-playwright-tests.result }}" == "skipped" ]]; then
            exit 0
          else
            exit 1
          fi

  upload-to-testdino:
    name: Upload Test Results to TestDino
    if: ${{ always() }}
    needs:
      - run-playwright-tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install testdino
        run: |
          python -m pip install --upgrade pip
          pip install testdino

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          merge-multiple: true
          path: combined-test-results

      - name: Merge JSON reports from all shards
        run: |
          cat > merge_reports.py << 'SCRIPT_EOF'
          import json
          from pathlib import Path
          from datetime import datetime
          
          combined_dir = Path("combined-test-results")
          json_reports = list(combined_dir.rglob("report.json"))
          
          if not json_reports:
              print("No report.json files found")
              exit(1)
          
          print(f"Found {len(json_reports)} JSON reports to merge")
          
          all_suites = []
          all_errors = []
          all_stats = {
              "total": 0,
              "passed": 0,
              "failed": 0,
              "skipped": 0,
              "flaky": 0,
              "expected": 0,
              "unexpected": 0,
              "duration": 0.0
          }
          config = None
          metadata = None
          earliest_start_time = None
          
          for report_path in json_reports:
              with open(report_path, "r") as f:
                  data = json.load(f)
                  
                  if config is None:
                      config = data.get("config", {})
                      if "shard" in config:
                          del config["shard"]
                  
                  if "suites" in data and isinstance(data["suites"], list):
                      all_suites.extend(data["suites"])
                  
                  if "errors" in data and isinstance(data["errors"], list):
                      all_errors.extend(data["errors"])
                  
                  if "stats" in data:
                      stats = data["stats"]
                      all_stats["total"] += stats.get("total", 0)
                      all_stats["passed"] += stats.get("passed", 0)
                      all_stats["failed"] += stats.get("failed", 0)
                      all_stats["skipped"] += stats.get("skipped", 0)
                      all_stats["flaky"] += stats.get("flaky", 0)
                      all_stats["expected"] += stats.get("expected", 0)
                      all_stats["unexpected"] += stats.get("unexpected", 0)
                      all_stats["duration"] += stats.get("duration", 0.0)
                      
                      start_time = stats.get("startTime")
                      if start_time:
                          if earliest_start_time is None or start_time < earliest_start_time:
                              earliest_start_time = start_time
                  
                  if metadata is None and "metadata" in data:
                      metadata = data.get("metadata")
          
          if earliest_start_time:
              all_stats["startTime"] = earliest_start_time
          else:
              all_stats["startTime"] = datetime.now().isoformat()
          
          merged_report = {
              "config": config or {},
              "suites": all_suites,
              "stats": all_stats,
              "errors": all_errors
          }
          
          if metadata:
              merged_report["metadata"] = metadata
          
          output_path = combined_dir / "report.json"
          with open(output_path, "w") as f:
              json.dump(merged_report, f, indent=2)
          
          print(f"âœ… Merged {len(json_reports)} reports into {output_path}")
          print(f"ðŸ“Š Total tests: {all_stats['total']} (passed: {all_stats['passed']}, failed: {all_stats['failed']}, skipped: {all_stats['skipped']}, flaky: {all_stats['flaky']})")
          print(f"â±ï¸  Total duration: {all_stats['duration']:.2f}s")
          SCRIPT_EOF
          python3 merge_reports.py

      - name: Upload to TestDino
        env:
          TESTDINO_TOKEN: ${{ secrets.TESTDINO_TOKEN }}
        run: |
          if [ -z "$TESTDINO_TOKEN" ]; then
            echo "TESTDINO_TOKEN not set, skipping upload"
            exit 0
          fi
          if [ -d "combined-test-results" ] && [ -n "$(ls -A combined-test-results 2>/dev/null)" ]; then
            # Basic upload - uploads merged JSON report
            testdino upload ./combined-test-results --token="$TESTDINO_TOKEN"
          else
            echo "No test results found to upload"
          fi